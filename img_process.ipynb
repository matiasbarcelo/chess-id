{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chess Board Detection and Chess Piece Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.spatial as spatial\n",
    "import scipy.cluster as clstr\n",
    "from time import time\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from sklearn.utils import shuffle\n",
    "import os, glob, skimage, cv2, shutil\n",
    "# import caffe\n",
    "\n",
    "SQUARE_SIDE_LENGTH = 227\n",
    "categories = ['bb', 'bk', 'bn', 'bp', 'bq', 'br', 'empty', 'wb', 'wk', 'wn', 'wp', 'wq', 'wr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Board Detection\n",
    "\n",
    "How it works:\n",
    "\n",
    "1. Canny edge detection\n",
    "2. Hough line transform\n",
    "3. calculate intersection points\n",
    "4. Agglomerative clustering of intersection points\n",
    "5. find corners\n",
    "6. perspective shift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def auto_canny(image, sigma=0.33):\n",
    "    \"\"\"\n",
    "    Canny edge detection with automatic thresholds.\n",
    "    \"\"\"\n",
    "    # compute the median of the single channel pixel intensities\n",
    "    v = np.median(image)\n",
    " \n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    edged = cv2.Canny(image, lower, upper)\n",
    " \n",
    "    # return the edged image\n",
    "    return edged\n",
    "\n",
    "def hor_vert_lines(lines):\n",
    "    \"\"\"\n",
    "    A line is given by rho and theta. Given a list of lines, returns a list of\n",
    "    horizontal lines (theta=90 deg) and a list of vertical lines (theta=0 deg).\n",
    "    \"\"\"\n",
    "    h = []\n",
    "    v = []\n",
    "    for distance, angle in lines:\n",
    "        if angle < np.pi / 4 or angle > np.pi - np.pi / 4:\n",
    "            v.append([distance, angle])\n",
    "        else:\n",
    "            h.append([distance, angle])\n",
    "    return h, v\n",
    "\n",
    "def intersections(h, v):\n",
    "    \"\"\"\n",
    "    Given lists of horizontal and vertical lines in (rho, theta) form, returns list\n",
    "    of (x, y) intersection points.\n",
    "    \"\"\"\n",
    "    points = []\n",
    "    for d1, a1 in h:\n",
    "        for d2, a2 in v:\n",
    "            A = np.array([[np.cos(a1), np.sin(a1)], [np.cos(a2), np.sin(a2)]])\n",
    "            b = np.array([d1, d2])\n",
    "            point = np.linalg.solve(A, b)\n",
    "            points.append(point)\n",
    "    return np.array(points)\n",
    "\n",
    "def cluster(points, max_dist=50):\n",
    "    \"\"\"\n",
    "    Given a list of points, returns a list of cluster centers.\n",
    "    \"\"\"\n",
    "    Y = spatial.distance.pdist(points)\n",
    "    Z = clstr.hierarchy.single(Y)\n",
    "    T = clstr.hierarchy.fcluster(Z, max_dist, 'distance')\n",
    "    clusters = defaultdict(list)\n",
    "    for i in range(len(T)):\n",
    "        clusters[T[i]].append(points[i])\n",
    "    clusters = clusters.values()\n",
    "    clusters = map(lambda arr: (np.mean(np.array(arr)[:,0]), np.mean(np.array(arr)[:,1])), clusters)\n",
    "    return clusters\n",
    "\n",
    "def closest_point(points, loc):\n",
    "    \"\"\"\n",
    "    Returns the list of points, sorted by distance from loc.\n",
    "    \"\"\"\n",
    "    dists = np.array(map(partial(spatial.distance.euclidean, loc), points))\n",
    "    return points[dists.argmin()]\n",
    "\n",
    "def find_corners(points, img_dim):\n",
    "    \"\"\"\n",
    "    Given a list of points, returns a list containing the four corner points.\n",
    "    \"\"\"\n",
    "    center_point = closest_point(points, (img_dim[0] / 2, img_dim[1] / 2))\n",
    "    points.remove(center_point)\n",
    "    center_adjacent_point = closest_point(points, center_point)\n",
    "    points.append(center_point)\n",
    "    grid_dist = spatial.distance.euclidean(np.array(center_point), np.array(center_adjacent_point))\n",
    "    \n",
    "    img_corners = [(0, 0), (0, img_dim[1]), img_dim, (img_dim[0], 0)]\n",
    "    board_corners = []\n",
    "    tolerance = 0.25 # bigger = more tolerance\n",
    "    for img_corner in img_corners:\n",
    "        while True:\n",
    "            cand_board_corner = closest_point(points, img_corner)\n",
    "            points.remove(cand_board_corner)\n",
    "            cand_board_corner_adjacent = closest_point(points, cand_board_corner)\n",
    "            corner_grid_dist = spatial.distance.euclidean(np.array(cand_board_corner), np.array(cand_board_corner_adjacent))\n",
    "            if corner_grid_dist > (1 - tolerance) * grid_dist and corner_grid_dist < (1 + tolerance) * grid_dist:\n",
    "                points.append(cand_board_corner)\n",
    "                board_corners.append(cand_board_corner)\n",
    "                break\n",
    "    return board_corners\n",
    "\n",
    "def four_point_transform(img, points, square_length=SQUARE_SIDE_LENGTH):\n",
    "    board_length = square_length * 8\n",
    "    pts1 = np.float32(points)\n",
    "    pts2 = np.float32([[0, 0], [0, board_length], [board_length, board_length], [board_length, 0]])\n",
    "    M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    return cv2.warpPerspective(img, M, (board_length, board_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'map' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 66\u001b[0m\n\u001b[0;32m     63\u001b[0m             arr\u001b[38;5;241m.\u001b[39mappend(img[i \u001b[38;5;241m*\u001b[39m sq_len : (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m sq_len, j \u001b[38;5;241m*\u001b[39m sq_len : (j \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m sq_len])\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\n\u001b[1;32m---> 66\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcrop.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mfind_board\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_image.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[7], line 43\u001b[0m, in \u001b[0;36mfind_board\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Find corners\u001b[39;00m\n\u001b[0;32m     42\u001b[0m img_shape \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mshape(img)\n\u001b[1;32m---> 43\u001b[0m points \u001b[38;5;241m=\u001b[39m \u001b[43mfind_corners\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m point \u001b[38;5;129;01min\u001b[39;00m points:\n",
      "Cell \u001b[1;32mIn[6], line 69\u001b[0m, in \u001b[0;36mfind_corners\u001b[1;34m(points, img_dim)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_corners\u001b[39m(points, img_dim):\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m    Given a list of points, returns a list containing the four corner points.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m     center_point \u001b[38;5;241m=\u001b[39m \u001b[43mclosest_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_dim\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_dim\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m     points\u001b[38;5;241m.\u001b[39mremove(center_point)\n\u001b[0;32m     71\u001b[0m     center_adjacent_point \u001b[38;5;241m=\u001b[39m closest_point(points, center_point)\n",
      "Cell \u001b[1;32mIn[6], line 63\u001b[0m, in \u001b[0;36mclosest_point\u001b[1;34m(points, loc)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03mReturns the list of points, sorted by distance from loc.\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     62\u001b[0m dists \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mmap\u001b[39m(partial(spatial\u001b[38;5;241m.\u001b[39mdistance\u001b[38;5;241m.\u001b[39meuclidean, loc), points))\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpoints\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdists\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'map' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "def find_board(fname):\n",
    "    \"\"\"\n",
    "    Given a filename, returns the board image.\n",
    "    \"\"\"\n",
    "    start = time()\n",
    "    img = cv2.imread(fname)\n",
    "    assert img is not None\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.blur(gray, (3, 3)) # TODO auto adjust the size of the blur\n",
    "    \n",
    "    # Canny edge detection\n",
    "    edges = auto_canny(gray)\n",
    "    assert np.count_nonzero(edges) / float(gray.shape[0] * gray.shape[1]) < 0.015\n",
    "\n",
    "    # Hough line detection\n",
    "    lines = cv2.HoughLines(edges, 1, np.pi/180, 200)\n",
    "    lines = np.reshape(lines, (-1, 2))\n",
    "    \n",
    "    # Compute intersection points\n",
    "    h, v = hor_vert_lines(lines)\n",
    "    # assert len(h) >= 9\n",
    "    # assert len(v) >= 9\n",
    "    points = intersections(h, v)\n",
    "        \n",
    "    if False:\n",
    "        for rho, theta in lines:\n",
    "            a = np.cos(theta)\n",
    "            b = np.sin(theta)\n",
    "            x0 = a*rho\n",
    "            y0 = b*rho\n",
    "            x1 = int(x0 + 4000*(-b))\n",
    "            y1 = int(y0 + 4000*(a))\n",
    "            x2 = int(x0 - 4000*(-b))\n",
    "            y2 = int(y0 - 4000*(a))\n",
    "            cv2.line(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "        cv2.imwrite('lines.jpg', img)\n",
    "    \n",
    "    # Cluster intersection points\n",
    "    points = cluster(points)\n",
    "    \n",
    "    # Find corners\n",
    "    img_shape = np.shape(img)\n",
    "    points = find_corners(points, (img_shape[1], img_shape[0]))\n",
    "    \n",
    "    if False:\n",
    "        for point in points:\n",
    "            cv2.circle(img, tuple(point), 25, (0,0,255), -1)\n",
    "        cv2.imwrite('points.jpg', img)\n",
    "    \n",
    "    # Perspective transform\n",
    "    new_img = four_point_transform(img, points)\n",
    "\n",
    "    return new_img\n",
    "\n",
    "def split_board(img):\n",
    "    \"\"\"\n",
    "    Given a board image, returns an array of 64 smaller images.\n",
    "    \"\"\"\n",
    "    arr = []\n",
    "    sq_len = img.shape[0] / 8\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            arr.append(img[i * sq_len : (i + 1) * sq_len, j * sq_len : (j + 1) * sq_len])\n",
    "    return arr\n",
    "\n",
    "cv2.imwrite('crop.jpg', find_board('test_image.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Training/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = {}\n",
    "with open('./labels.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        if line[0] == '#':\n",
    "            continue\n",
    "        arr = line.split()\n",
    "        assert len(arr) == 2\n",
    "        assert arr[0] not in labels\n",
    "        labels[arr[0]] = arr[1]\n",
    "\n",
    "def get_label_arr(key):\n",
    "    \"\"\"\n",
    "    Get the list of piece labels for the specific image number.\n",
    "    \n",
    "    key: The image number\n",
    "    returns: List of piece labels, e.g. ['empty', 'wn', 'empty', ...]\n",
    "    \"\"\"\n",
    "    fen = labels[key]\n",
    "    fen = fen.replace('1', '_')\n",
    "    fen = fen.replace('2', '__')\n",
    "    fen = fen.replace('3', '___')\n",
    "    fen = fen.replace('4', '____')\n",
    "    fen = fen.replace('5', '_____')\n",
    "    fen = fen.replace('6', '______')\n",
    "    fen = fen.replace('7', '_______')\n",
    "    fen = fen.replace('8', '________')\n",
    "    fen = fen.replace('/', '')\n",
    "    arr = []\n",
    "    for char in fen:\n",
    "        if char == '_':\n",
    "            arr.append('empty')\n",
    "        elif char == 'x':\n",
    "            arr.append('del')\n",
    "        elif char.islower():\n",
    "            arr.append('b' + char.lower())\n",
    "        else:\n",
    "            arr.append('w' + char.lower())\n",
    "    assert len(arr) == 64\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0%\n",
      "20.0%\n",
      "30.0%\n",
      "40.0%\n",
      "50.0%\n",
      "60.0%\n",
      "70.0%\n",
      "80.0%\n",
      "90.0%\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DIRS = {'input': './pictures_train/', 'intermediate': './crops_train/', 'output': './output_train/'}\n",
    "TEST_DIRS = {'input': './pictures_test/', 'intermediate': './crops_test/', 'output': './output_test/'}\n",
    "\n",
    "M_90deg_rotation = cv2.getRotationMatrix2D((SQUARE_SIDE_LENGTH / 2, SQUARE_SIDE_LENGTH / 2), 90, 1)\n",
    "\n",
    "def write_augmented_output(output_dir, img_num, images, labels):\n",
    "    for i in range(len(images)):\n",
    "        if labels[i] == 'del':\n",
    "            continue\n",
    "        if not os.path.exists(output_dir + labels[i]):\n",
    "            os.makedirs(output_dir + labels[i])\n",
    "        img_90 = cv2.warpAffine(images[i], M_90deg_rotation, (SQUARE_SIDE_LENGTH, SQUARE_SIDE_LENGTH))\n",
    "        img_180 = cv2.warpAffine(img_90, M_90deg_rotation, (SQUARE_SIDE_LENGTH, SQUARE_SIDE_LENGTH))\n",
    "        img_270 = cv2.warpAffine(img_180, M_90deg_rotation, (SQUARE_SIDE_LENGTH, SQUARE_SIDE_LENGTH))\n",
    "        cv2.imwrite(output_dir + labels[i] + '/' + img_num + '_' + str(i) + '.jpg', images[i])\n",
    "        cv2.imwrite(output_dir + labels[i] + '/' + img_num + '_' + str(i) + '_90.jpg', img_90)\n",
    "        cv2.imwrite(output_dir + labels[i] + '/' + img_num + '_' + str(i) + '_180.jpg', img_180)\n",
    "        cv2.imwrite(output_dir + labels[i] + '/' + img_num + '_' + str(i) + '_270.jpg', img_270)\n",
    "\n",
    "def gen_data(dir_dict):\n",
    "    for path in dir_dict.values():\n",
    "        assert path[-1] == '/'\n",
    "    shutil.rmtree(dir_dict['intermediate'], True)\n",
    "    shutil.rmtree(dir_dict['output'], True)\n",
    "    os.makedirs(dir_dict['intermediate'])\n",
    "    os.makedirs(dir_dict['output'])\n",
    "    \n",
    "    input_paths = glob.glob(dir_dict['input'] + '*.jpg')\n",
    "    percent = 0\n",
    "    for i in range(len(input_paths)):\n",
    "        new_percent = 100 * float(i) / len(input_paths)\n",
    "        if new_percent > percent + 5:\n",
    "            percent = new_percent\n",
    "            print str(percent) + '%'\n",
    "        \n",
    "        input_path = input_paths[i]\n",
    "        input_img_num = input_path[input_path.rfind('_') + 1 : input_path.rfind('.')]\n",
    "        board = find_board(input_path)\n",
    "        cv2.imwrite(dir_dict['intermediate'] + input_img_num + '.jpg', board)\n",
    "        piece_images = split_board(board)\n",
    "        piece_labels = get_label_arr(input_img_num)\n",
    "        write_augmented_output(dir_dict['output'], input_img_num, piece_images, piece_labels)\n",
    "    print 'Done'\n",
    "\n",
    "\n",
    "gen_data(TEST_DIRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caffe list file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def get_label_for_fname(fname):\n",
    "    for i in range(len(categories)):\n",
    "        if '/' + categories[i] + '/' in fname:\n",
    "            return str(i)\n",
    "    raise\n",
    "\n",
    "fnames = glob.glob(TRAIN_DIRS['output'] + '*/*.jpg')\n",
    "fnames = shuffle(map(os.path.abspath, fnames))\n",
    "with open('caffe_train.txt', 'w+') as f:\n",
    "    for fname in fnames:\n",
    "        f.write(fname + ' ' + get_label_for_fname(fname) + '\\n')\n",
    "        \n",
    "fnames = glob.glob(TEST_DIRS['output'] + '*/*.jpg')\n",
    "fnames = shuffle(map(os.path.abspath, fnames))\n",
    "with open('caffe_test.txt', 'w+') as f:\n",
    "    for fname in fnames:\n",
    "        f.write(fname + ' ' + get_label_for_fname(fname) + '\\n')\n",
    "\n",
    "print 'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 131.33953259  145.51087425  134.98660675]\n"
     ]
    }
   ],
   "source": [
    "# Compute mean\n",
    "\n",
    "fnames = glob.glob(TRAIN_DIRS['intermediate'] + '*.jpg')\n",
    "means = None\n",
    "for fname in fnames:\n",
    "    this_mean = np.mean(np.reshape(cv2.imread(fname), (-1, 3)), axis=0)\n",
    "    if means is None:\n",
    "        means = this_mean\n",
    "    else:\n",
    "        means = np.vstack((means, this_mean))\n",
    "means = np.mean(means, axis=0) # bgr\n",
    "print means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting boards with the Caffe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = caffe.Net('/Users/daylenyang/caffe/models/finetune_chess/deploy.prototxt',\n",
    "               '/Users/daylenyang/caffe/models/finetune_chess/finetune_chess_iter_5554.caffemodel',\n",
    "               caffe.TEST)\n",
    "\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "transformer.set_transpose('data', (2,0,1))\n",
    "transformer.set_mean('data', np.load('/Users/daylenyang/caffe/python/caffe/imagenet/ilsvrc_2012_mean.npy').mean(1).mean(1)) # mean pixel\n",
    "transformer.set_raw_scale('data', 255)  # the reference model operates on images in [0,255] range instead of [0,1]\n",
    "transformer.set_channel_swap('data', (2,1,0))  # the reference model has channels in BGR order instead of RGB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shrink_blanks(fen):\n",
    "    if '_' not in fen:\n",
    "        return fen\n",
    "    new_fen = ''\n",
    "    blanks = 0\n",
    "    for char in fen:\n",
    "        if char == '_':\n",
    "            blanks += 1\n",
    "        else:\n",
    "            if blanks != 0:\n",
    "                new_fen += str(blanks)\n",
    "                blanks = 0\n",
    "            new_fen += char\n",
    "    if blanks != 0:\n",
    "        new_fen += str(blanks)\n",
    "    return new_fen\n",
    "\n",
    "def get_fen(arr):\n",
    "    fen = ''\n",
    "    for sq in arr:\n",
    "        if sq == 'empty':\n",
    "            fen += '_'\n",
    "        elif sq[0] == 'b':\n",
    "            fen += sq[1]\n",
    "        else:\n",
    "            fen += str(sq[1]).upper()\n",
    "    fens = [fen[i:i+8] for i in range(0, 64, 8)]\n",
    "    fens = map(shrink_blanks, fens)\n",
    "    fen = '/'.join(fens)\n",
    "    return fen\n",
    "\n",
    "def get_square_to_pieces_dict(prob_matrix):\n",
    "    d = {}\n",
    "    for i in range(len(prob_matrix)):\n",
    "        d[i] = map(lambda x: categories[x], np.argsort(-prob_matrix[i]))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished board splitting 0.352416992188 sec\n",
      "finished input preprocessing 0.775801897049 sec\n",
      "8/5k2/r7/3N1NPP/8/8/8/8\n",
      "finished nn 1.6532959938 sec\n",
      "took 1.65340399742 sec\n"
     ]
    }
   ],
   "source": [
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()\n",
    "start = time()\n",
    "\n",
    "board = find_board('./pictures_test/IMG_0983.jpg')\n",
    "squares = split_board(board)\n",
    "print 'finished board splitting', time() - start, 'sec'\n",
    "net.blobs['data'].reshape(64,3,227,227)\n",
    "input_images = [transformer.preprocess('data', skimage.img_as_float(square).astype(np.float32)) for square in squares]\n",
    "print 'finished input preprocessing', time() - start, 'sec'\n",
    "net.blobs['data'].data[...] = np.array(input_images)\n",
    "out = net.forward()['prob']\n",
    "print get_fen(map(lambda x: categories[x], np.argmax(out, axis=1)))\n",
    "print 'finished nn', time() - start, 'sec'\n",
    "    \n",
    "print 'took', time() - start, 'sec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
